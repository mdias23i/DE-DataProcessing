{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdias23i/DE-DataProcessing/blob/main/spark/examples/06-write_partitioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA_wQSmLd9z"
      },
      "source": [
        "# Write\n",
        "- .write\n",
        "- .format (parquet, csv, json)\n",
        "- options\n",
        "- spark.sql.sources.partitionOverwriteMode dynamic\n",
        "\n",
        "# Write Mode\n",
        "- overwrite - The overwrite mode is used to overwrite the existing file, alternatively, you can use SaveMode.Overwrite\n",
        "- append - To add the data to the existing file, alternatively, you can use SaveMode.Append\n",
        "- ignore - Ignores write operation when the file already exists, alternatively, you can use SaveMode.Ignore.\n",
        "- errorifexists or error - This is a default option when the file already exists, it returns an error, alternatively, you can use SaveMode.ErrorIfExists.\n",
        "\n",
        "# Partitioning\n",
        "Process to organize the data into multiple chunks based on some criteria.\n",
        "Partitions are organized in sub-folders.\n",
        "Partitioning improves performance in Spark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "c410e46c-4a50-43aa-926f-d0417c6280d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "637HFw00T3LP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local').appName('Spark Course').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj3Cg2riVX3m"
      },
      "source": [
        "# Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83BBHcNJDmw4",
        "outputId": "86a2bc93-efe6-4b4c-8ce1-7e0dc9e9701d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-33.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from faker) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Downloading Faker-33.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-33.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z-caHS2MVX3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b971d5-eb8a-4ecb-d4c8-9fe74f20a42a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+--------------------------+----------+-----------------------+--------------------+--------------------+\n",
            "|address                                                 |date                      |dob       |email                  |name                |phone               |\n",
            "+--------------------------------------------------------+--------------------------+----------+-----------------------+--------------------+--------------------+\n",
            "|24647 Carmen Mall\\nPort Donnaview, ME 69957             |2024-05-01 18:28:09.301006|1945-07-24|graybrian@example.org  |Jason Dunlap        |(668)492-0513       |\n",
            "|06846 Mills Dale Suite 012\\nBrianside, MO 38344         |2024-05-01 14:49:29.585798|1956-06-16|jason53@example.org    |Andrew James        |001-548-973-2383x852|\n",
            "|107 Robles Wells\\nPort Michelle, PW 58336               |2024-05-03 19:00:37.186797|1946-02-21|hlittle@example.com    |Lisa Roberts        |(916)863-3834x0794  |\n",
            "|88632 Rodney Plain\\nLake Jasontown, GU 30158            |2024-05-04 14:08:01.797718|1999-06-19|lisa05@example.org     |Lucas Arnold        |413.891.0923x9693   |\n",
            "|51846 Scott Mountains Apt. 803\\nWest Nathaniel, MA 75060|2024-05-02 17:01:44.027161|1992-12-27|rodney65@example.net   |Russell Cox         |3144378208          |\n",
            "|507 Horton View\\nReynoldsberg, HI 08633                 |2024-05-04 05:33:22.64087 |1936-12-25|cameron33@example.com  |Elizabeth Pennington|(897)648-7194x310   |\n",
            "|USCGC Golden\\nFPO AE 85823                              |2024-05-04 20:29:36.10442 |2007-03-08|bryantryan@example.net |Donald Medina       |(358)874-9044x12850 |\n",
            "|5392 Megan Lights Apt. 594\\nNew Jaredmouth, AS 48250    |2024-05-04 18:58:25.524702|1984-03-28|kurt36@example.net     |Thomas Evans        |617.963.4211        |\n",
            "|565 Jonathan Square Apt. 711\\nZacharyland, IN 29224     |2024-05-03 16:49:34.399764|1937-04-02|joshuabaker@example.com|Benjamin Patton     |(437)335-5451x103   |\n",
            "|16120 James Lakes\\nLake Alicia, WY 75776                |2024-05-02 11:35:22.707322|1936-08-19|jayford@example.com    |Jamie Ramirez       |+1-899-543-8290     |\n",
            "+--------------------------------------------------------+--------------------------+----------+-----------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from faker import Faker\n",
        "from datetime import datetime\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "users = []\n",
        "for _ in range(50):\n",
        "    user = {\n",
        "        'date': fake.date_time_between_dates(datetime(2024, 5, 1), datetime(2024, 5, 5)),\n",
        "        'name': fake.name(),\n",
        "        'address': fake.address(),\n",
        "        'email': fake.email(),\n",
        "        'dob': fake.date_of_birth(),\n",
        "        'phone': fake.phone_number()\n",
        "    }\n",
        "    users.append(user)\n",
        "\n",
        "df = spark.createDataFrame(users)\n",
        "\n",
        "df.show(10, False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGXjf6xpBj36"
      },
      "source": [
        "# Writing as PARQUET\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14stpbb4Bj37"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw5IIgebBj37",
        "outputId": "eacfc1aa-132f-4be0-aa12-1620db1a6e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-3f09c745-5727-4b55-97b9-f219dbf703e3-c000.snappy.parquet  _SUCCESS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Writing as PARQUET with no partitions\n",
        "\n",
        "path = \"/content/write_partitioning/parquet_no_partitions\"\n",
        "\n",
        "df.write.mode(\"overwrite\").format(\"parquet\").save(path)\n",
        "\n",
        "!ls /content/write_partitioning/parquet_no_partitions\n",
        "\n",
        "spark.read.format(\"parquet\").load(path).count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing as PARQUET with partitions\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "path = \"/content/write_partitioning/parquet_with_partitions\"\n",
        "\n",
        "# Creating partition column\n",
        "df = df.withColumn(\"date_part\", date_format(col(\"date\"), \"yyyyMMdd\"))\n",
        "\n",
        "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\") # enable dynamic partition overwrite - only overwrites partitions that are coming in the dataframe\n",
        "\n",
        "(df#.where(\"date_part = '20240503'\")\n",
        " .write\n",
        " .mode(\"overwrite\")                                               # overwrites the entire path with the new data\n",
        " .partitionBy(\"date_part\")                                        # partition the data by column - creates sub-folders for each partition\n",
        " .format(\"parquet\")                                               # format of output\n",
        " .save(path))                                                     # path\n",
        "\n",
        "!ls /content/write_partitioning/parquet_with_partitions\n",
        "\n",
        "spark.read.format(\"parquet\").load(path).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWX9WZbPHrL1",
        "outputId": "0313082d-3531-4722-f6b1-3950c81ee49d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'date_part=20240501'  'date_part=20240502'  'date_part=20240503'  'date_part=20240504'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking single partition\n",
        "spark.read.parquet(\"/content/write_partitioning/parquet_with_partitions/date_part=20240502\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B62qu87JsAB",
        "outputId": "47c56171-78ab-4a9d-b054-9608638c3d80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------+--------------------+---------------+--------------------+\n",
            "|             address|                date|       dob|               email|           name|               phone|\n",
            "+--------------------+--------------------+----------+--------------------+---------------+--------------------+\n",
            "|51846 Scott Mount...|2024-05-02 17:01:...|1992-12-27|rodney65@example.net|    Russell Cox|          3144378208|\n",
            "|16120 James Lakes...|2024-05-02 11:35:...|1936-08-19| jayford@example.com|  Jamie Ramirez|     +1-899-543-8290|\n",
            "|8263 Jermaine Wal...|2024-05-02 19:02:...|1957-09-17| zsnyder@example.net| Erin Castaneda|001-512-806-6732x...|\n",
            "|224 Kemp Row Apt....|2024-05-02 00:28:...|1989-04-12|  psmith@example.net|Willie Mcdonald|  257-557-4643x12304|\n",
            "|1285 Eric Gateway...|2024-05-02 20:12:...|1941-04-28|kimberlyirwin@exa...|  Ashley Guzman|001-926-842-7730x...|\n",
            "|79212 Nicole Fiel...|2024-05-02 00:04:...|1915-02-10|mannjaime@example...|Elizabeth Logan|  (494)475-4997x7362|\n",
            "|09890 Lori Light\\...|2024-05-02 12:27:...|1909-05-18|michael06@example...|Elizabeth Meyer|   593.890.3264x9293|\n",
            "|32655 Dennis Mill...|2024-05-02 16:29:...|1914-08-05|daniellenewman@ex...| Craig Thompson|+1-354-512-1817x0...|\n",
            "|3014 Miller Track...|2024-05-02 12:53:...|2004-08-31|brianponce@exampl...| Nicholas Smith|+1-870-827-3522x5...|\n",
            "|6939 William Spri...|2024-05-02 17:38:...|1958-11-11|  yhardy@example.com|  Rachael Chase|+1-525-617-4738x4...|\n",
            "|154 Adams Islands...|2024-05-02 07:28:...|1916-07-17|turnerjames@examp...| Mark Blanchard|        968.566.1993|\n",
            "|43576 Reyes Inlet...|2024-05-02 03:15:...|1944-04-02|ryanhayes@example...| Benjamin Arias|   402-945-3842x8368|\n",
            "+--------------------+--------------------+----------+--------------------+---------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing as CSV\n",
        "\n",
        "https://spark.apache.org/docs/3.5.1/sql-data-sources-csv.html"
      ],
      "metadata": {
        "id": "n8mTC5yeNV6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnAWUTeZO43Z",
        "outputId": "39bae5a6-c91e-47cb-e9fe-475490175707"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/write_partitioning/csv_no_partitioning/\"\n",
        "\n",
        "# write as csv\n",
        "(df\n",
        "  .write\n",
        "  .format(\"csv\")\n",
        "  .mode(\"overwrite\")\n",
        "  .option(\"delimiter\", \"|\")\n",
        "  .option(\"header\", True)\n",
        "  .save(path))\n",
        "\n",
        "# listing files in the folder\n",
        "!ls /content/write_partitioning/csv_no_partitioning/\n",
        "\n",
        "# read as csv\n",
        "(spark\n",
        "  .read\n",
        "  .options(sep=\"|\", multiLine=True, header=True)\n",
        "  .csv(path)\n",
        "  .count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE6zC-HnNYAz",
        "outputId": "87658a72-4cb2-492f-8995-1e90273adf88"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-714d7354-65e9-4aa9-948b-9f76747e2cee-c000.csv  _SUCCESS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing as JSON\n",
        "\n",
        "https://spark.apache.org/docs/3.5.1/sql-data-sources-json.html"
      ],
      "metadata": {
        "id": "ZAuM5-WcTtyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/write_partitioning/json_no_partitioning/\"\n",
        "\n",
        "# write as json\n",
        "(df\n",
        ".write\n",
        ".mode(\"overwrite\")\n",
        ".format(\"json\")\n",
        ".save(path))\n",
        "\n",
        "# listing files in the folder\n",
        "!ls /content/write_partitioning/json_no_partitioning/\n",
        "\n",
        "# read as json\n",
        "(spark\n",
        "  .read\n",
        "  .json(path)\n",
        "  .count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnNgwbtxTsW_",
        "outputId": "93af3b90-97ee-438d-d4f5-b9dacc32fbda"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-b7d5210d-787a-4e93-b06d-81de03f3da7e-c000.json  _SUCCESS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading json as text\n",
        "spark.read.text(path).show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3hYNCubT0ry",
        "outputId": "6fc08e9e-0f83-4293-dc47-d7c4bd68589c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                               |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{\"address\":\"24647 Carmen Mall\\nPort Donnaview, ME 69957\",\"date\":\"2024-05-01T18:28:09.301Z\",\"dob\":\"1945-07-24\",\"email\":\"graybrian@example.org\",\"name\":\"Jason Dunlap\",\"phone\":\"(668)492-0513\",\"date_part\":\"20240501\"}                 |\n",
            "|{\"address\":\"06846 Mills Dale Suite 012\\nBrianside, MO 38344\",\"date\":\"2024-05-01T14:49:29.585Z\",\"dob\":\"1956-06-16\",\"email\":\"jason53@example.org\",\"name\":\"Andrew James\",\"phone\":\"001-548-973-2383x852\",\"date_part\":\"20240501\"}        |\n",
            "|{\"address\":\"107 Robles Wells\\nPort Michelle, PW 58336\",\"date\":\"2024-05-03T19:00:37.186Z\",\"dob\":\"1946-02-21\",\"email\":\"hlittle@example.com\",\"name\":\"Lisa Roberts\",\"phone\":\"(916)863-3834x0794\",\"date_part\":\"20240503\"}                |\n",
            "|{\"address\":\"88632 Rodney Plain\\nLake Jasontown, GU 30158\",\"date\":\"2024-05-04T14:08:01.797Z\",\"dob\":\"1999-06-19\",\"email\":\"lisa05@example.org\",\"name\":\"Lucas Arnold\",\"phone\":\"413.891.0923x9693\",\"date_part\":\"20240504\"}               |\n",
            "|{\"address\":\"51846 Scott Mountains Apt. 803\\nWest Nathaniel, MA 75060\",\"date\":\"2024-05-02T17:01:44.027Z\",\"dob\":\"1992-12-27\",\"email\":\"rodney65@example.net\",\"name\":\"Russell Cox\",\"phone\":\"3144378208\",\"date_part\":\"20240502\"}         |\n",
            "|{\"address\":\"507 Horton View\\nReynoldsberg, HI 08633\",\"date\":\"2024-05-04T05:33:22.640Z\",\"dob\":\"1936-12-25\",\"email\":\"cameron33@example.com\",\"name\":\"Elizabeth Pennington\",\"phone\":\"(897)648-7194x310\",\"date_part\":\"20240504\"}         |\n",
            "|{\"address\":\"USCGC Golden\\nFPO AE 85823\",\"date\":\"2024-05-04T20:29:36.104Z\",\"dob\":\"2007-03-08\",\"email\":\"bryantryan@example.net\",\"name\":\"Donald Medina\",\"phone\":\"(358)874-9044x12850\",\"date_part\":\"20240504\"}                          |\n",
            "|{\"address\":\"5392 Megan Lights Apt. 594\\nNew Jaredmouth, AS 48250\",\"date\":\"2024-05-04T18:58:25.524Z\",\"dob\":\"1984-03-28\",\"email\":\"kurt36@example.net\",\"name\":\"Thomas Evans\",\"phone\":\"617.963.4211\",\"date_part\":\"20240504\"}            |\n",
            "|{\"address\":\"565 Jonathan Square Apt. 711\\nZacharyland, IN 29224\",\"date\":\"2024-05-03T16:49:34.399Z\",\"dob\":\"1937-04-02\",\"email\":\"joshuabaker@example.com\",\"name\":\"Benjamin Patton\",\"phone\":\"(437)335-5451x103\",\"date_part\":\"20240503\"}|\n",
            "|{\"address\":\"16120 James Lakes\\nLake Alicia, WY 75776\",\"date\":\"2024-05-02T11:35:22.707Z\",\"dob\":\"1936-08-19\",\"email\":\"jayford@example.com\",\"name\":\"Jamie Ramirez\",\"phone\":\"+1-899-543-8290\",\"date_part\":\"20240502\"}                   |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading json as text\n",
        "spark.read.json(path).show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bHcT2ilUo_F",
        "outputId": "b1aeda4e-1a0d-4d89-a575-921ea7992693"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+------------------------+---------+----------+-----------------------+--------------------+--------------------+\n",
            "|address                                                 |date                    |date_part|dob       |email                  |name                |phone               |\n",
            "+--------------------------------------------------------+------------------------+---------+----------+-----------------------+--------------------+--------------------+\n",
            "|24647 Carmen Mall\\nPort Donnaview, ME 69957             |2024-05-01T18:28:09.301Z|20240501 |1945-07-24|graybrian@example.org  |Jason Dunlap        |(668)492-0513       |\n",
            "|06846 Mills Dale Suite 012\\nBrianside, MO 38344         |2024-05-01T14:49:29.585Z|20240501 |1956-06-16|jason53@example.org    |Andrew James        |001-548-973-2383x852|\n",
            "|107 Robles Wells\\nPort Michelle, PW 58336               |2024-05-03T19:00:37.186Z|20240503 |1946-02-21|hlittle@example.com    |Lisa Roberts        |(916)863-3834x0794  |\n",
            "|88632 Rodney Plain\\nLake Jasontown, GU 30158            |2024-05-04T14:08:01.797Z|20240504 |1999-06-19|lisa05@example.org     |Lucas Arnold        |413.891.0923x9693   |\n",
            "|51846 Scott Mountains Apt. 803\\nWest Nathaniel, MA 75060|2024-05-02T17:01:44.027Z|20240502 |1992-12-27|rodney65@example.net   |Russell Cox         |3144378208          |\n",
            "|507 Horton View\\nReynoldsberg, HI 08633                 |2024-05-04T05:33:22.640Z|20240504 |1936-12-25|cameron33@example.com  |Elizabeth Pennington|(897)648-7194x310   |\n",
            "|USCGC Golden\\nFPO AE 85823                              |2024-05-04T20:29:36.104Z|20240504 |2007-03-08|bryantryan@example.net |Donald Medina       |(358)874-9044x12850 |\n",
            "|5392 Megan Lights Apt. 594\\nNew Jaredmouth, AS 48250    |2024-05-04T18:58:25.524Z|20240504 |1984-03-28|kurt36@example.net     |Thomas Evans        |617.963.4211        |\n",
            "|565 Jonathan Square Apt. 711\\nZacharyland, IN 29224     |2024-05-03T16:49:34.399Z|20240503 |1937-04-02|joshuabaker@example.com|Benjamin Patton     |(437)335-5451x103   |\n",
            "|16120 James Lakes\\nLake Alicia, WY 75776                |2024-05-02T11:35:22.707Z|20240502 |1936-08-19|jayford@example.com    |Jamie Ramirez       |+1-899-543-8290     |\n",
            "+--------------------------------------------------------+------------------------+---------+----------+-----------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# partition json data + saveAsTable\n",
        "\n",
        "# Creating partition column\n",
        "df = df.withColumn(\"date_part\", date_format(col(\"date\"), \"yyyyMMdd\"))\n",
        "\n",
        "# write as json\n",
        "(df.write\n",
        "  .partitionBy(\"date_part\")\n",
        "  .mode(\"overwrite\")\n",
        "  .format(\"json\")\n",
        "  .saveAsTable(\"tbl_json_part\"))\n",
        "\n",
        "# read as json\n",
        "print(spark.table(\"tbl_json_part\").count())\n",
        "\n",
        "# read as json\n",
        "spark.sql(\"show partitions tbl_json_part\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj59UNMuU0hV",
        "outputId": "483fa991-fd6d-4469-e2b9-ea581a42f586"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "+------------------+\n",
            "|         partition|\n",
            "+------------------+\n",
            "|date_part=20240501|\n",
            "|date_part=20240502|\n",
            "|date_part=20240503|\n",
            "|date_part=20240504|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Append Mode"
      ],
      "metadata": {
        "id": "6RhijzyqZeeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing as PARQUET with APPEND\n",
        "\n",
        "path = \"/content/write_partitioning/parquet_append\"\n",
        "\n",
        "df.write.mode(\"append\").format(\"parquet\").save(path)\n",
        "\n",
        "!ls /content/write_partitioning/parquet_append\n",
        "\n",
        "spark.read.format(\"parquet\").load(path).count()"
      ],
      "metadata": {
        "id": "GmLjA1zDZeG_",
        "outputId": "787e7b71-e956-454e-c9a8-7a7a96962f46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-297caa6f-52e2-41ac-bb50-9598d31798e8-c000.snappy.parquet  _SUCCESS\n",
            "part-00000-30a73df1-3e66-40c1-a756-2814d529955c-c000.snappy.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}